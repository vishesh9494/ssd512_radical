{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TerminateOnNaN, CSVLogger\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import os.path\n",
    "import os\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "from PIL import Image, ImageFont, ImageDraw, ImageEnhance\n",
    "from numpy import *\n",
    "import random\n",
    "import sys\n",
    "import csv\n",
    "from skimage.transform import PiecewiseAffineTransform, warp\n",
    "from skimage import data\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set the model configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 300 # Height of the input images\n",
    "img_width = 300 # Width of the input images\n",
    "\n",
    "img_channels = 3 # Number of color channels of the input images\n",
    "\n",
    "mean_color = [123, 117, 104] # The per-channel mean of the images in the dataset. Do not change this value if you're using any of the pre-trained weights.\n",
    "\n",
    "subtract_mean = [123, 117, 104] # The per-channel mean of the images in the dataset\n",
    "\n",
    "swap_channels = [2, 1, 0] # The color channel order in the original SSD is BGR, so we should set this to `True`, but weirdly the results are better without swapping.\n",
    "\n",
    "# TODO: Set the number of classes.\n",
    "n_classes = 1 \n",
    "\n",
    "# The anchor box scaling factors used in the original SSD512\n",
    "scales = [0.07, 0.15, 0.3, 0.45, 0.6, 0.75, 0.9, 1.05]\n",
    "\n",
    "# The anchor box aspect ratios used in the original SSD512; the order matters\n",
    "aspect_ratios = [[1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5]]\n",
    "\n",
    "two_boxes_for_ar1 = True\n",
    "\n",
    "steps = [8, 16, 32, 64, 128, 256, 512] # The space between two adjacent anchor box center points for each predictor layer.\n",
    "\n",
    "offsets = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5] # The offsets of the first anchor box center points from the top and left borders of the image as a fraction of the step size for each predictor layer.\n",
    "\n",
    "clip_boxes = False # Whether or not you want to limit the anchor boxes to lie entirely within the image boundaries\n",
    "\n",
    "variances = [0.1, 0.1, 0.2, 0.2] # The variances by which the encoded target coordinates are scaled as in the original implementation\n",
    "\n",
    "normalize_coords = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set the path to the `.h5` file of the model to be loaded.\n",
    "model_path = os.getcwd() + '/model/' + 'ssd512_radical_HSM.h5'\n",
    "\n",
    "# We need to create an SSDLoss object in order to pass that to the model loader.\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = load_model(model_path, custom_objects={'AnchorBoxes': AnchorBoxes,\n",
    "                                               'L2Normalization': L2Normalization,\n",
    "                                               'compute_loss': ssd_loss.compute_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load some images\n",
    "\n",
    "Load some images for which you'd like the model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path=None)\n",
    "\n",
    "images_dir_test = 'images\\\\'\n",
    "\n",
    "# Generate CSV file for the images\n",
    "\n",
    "labels_format = ['image_name','xmin','xmax','ymin','ymax','class_id']\n",
    "\n",
    "csv_file_test = open('labels_test.csv', 'a', newline='')\n",
    "writer_test = csv.DictWriter(csv_file_test, fieldnames=labels_format)\n",
    "writer_test.writeheader()\n",
    "\n",
    "images_raw_list = os.listdir(images_dir_test)\n",
    "\n",
    "for file in images_raw_list:\n",
    "    writer_test.writerow({'image_name': file, 'xmin': str(0), 'xmax': str(5), 'ymin': str(0), 'ymax': str(5), 'class_id': str(1)})\n",
    "    \n",
    "csv_file_test.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_filename_test = 'labels_test.csv'\n",
    "\n",
    "val_dataset.parse_csv(images_dir = images_dir_test,\n",
    "                       labels_filename = labels_filename_test,\n",
    "                       input_format = labels_format,\n",
    "                       include_classes = 'all',\n",
    "                       random_sample = False,\n",
    "                       ret = False,\n",
    "                       verbose = True)\n",
    "\n",
    "# For the validation generator:\n",
    "convert_to_3_channels = ConvertTo3Channels()\n",
    "resize = Resize(height=img_height, width=img_width)\n",
    "\n",
    "# The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.\n",
    "predictor_sizes = [model.get_layer('conv4_3_norm_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('fc7_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv6_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv7_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv8_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv9_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv10_2_mbox_conf').output_shape[1:3]]\n",
    "\n",
    "ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
    "                                    img_width=img_width,\n",
    "                                    n_classes=n_classes,\n",
    "                                    predictor_sizes=predictor_sizes,\n",
    "                                    scales=scales,\n",
    "                                    aspect_ratios_per_layer=aspect_ratios,\n",
    "                                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                    steps=steps,\n",
    "                                    offsets=offsets,\n",
    "                                    clip_boxes=clip_boxes,\n",
    "                                    variances=variances,\n",
    "                                    matching_type='multi',\n",
    "                                    pos_iou_threshold=0.5,\n",
    "                                    neg_iou_limit=0.5,\n",
    "                                    normalize_coords=normalize_coords)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "val_generator = val_dataset.generate(batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     transformations=[convert_to_3_channels,\n",
    "                                                      resize],\n",
    "                                     label_encoder=ssd_input_encoder,\n",
    "                                     returns={'processed_images',\n",
    "                                              'encoded_labels'},\n",
    "                                     keep_images_without_gt=False)\n",
    "\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the test dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make predictions and save the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the generator for the predictions.\n",
    "\n",
    "predict_generator = val_dataset.generate(batch_size=1,\n",
    "                                         shuffle=True,\n",
    "                                         transformations=[convert_to_3_channels,\n",
    "                                                          resize],\n",
    "                                         label_encoder=None,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'filenames',\n",
    "                                                  'inverse_transform',\n",
    "                                                  'original_images',\n",
    "                                                  'original_labels'},\n",
    "                                         keep_images_without_gt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate samples.\n",
    "\n",
    "for l in range(val_dataset_size):\n",
    "    batch_images, batch_filenames, batch_inverse_transforms, batch_original_images, batch_original_labels = next(predict_generator)\n",
    "\n",
    "    i = 0 # Which batch item to look at\n",
    "    \n",
    "    # Make predictions.\n",
    "\n",
    "    y_pred = model.predict(batch_images)\n",
    "    \n",
    "    # Decode the raw predictions in `y_pred`.\n",
    "\n",
    "    y_pred_decoded = decode_detections(y_pred,\n",
    "                                       confidence_thresh=0.0001,\n",
    "                                       iou_threshold=0.4,\n",
    "                                       top_k=200,\n",
    "                                       normalize_coords=normalize_coords,\n",
    "                                       img_height=img_height,\n",
    "                                       img_width=img_width)\n",
    "    \n",
    "     # Convert the predictions for the original image.\n",
    "\n",
    "    y_pred_decoded_inv = apply_inverse_transforms(y_pred_decoded, batch_inverse_transforms)\n",
    "    \n",
    "    predicted = []\n",
    "    length = len(y_pred_decoded_inv[i])\n",
    "    \n",
    "    if length is not 0:\n",
    "        pred_list = y_pred_decoded_inv[i].tolist()\n",
    "\n",
    "        if(length != 1):\n",
    "            for kk in range(len(pred_list)):\n",
    "                predicted.append(pred_list[kk])\n",
    "        else:\n",
    "            predicted = pred_list\n",
    "\n",
    "        np.set_printoptions(precision=2, suppress=True, linewidth=90)\n",
    "        # best predicted box:\n",
    "        np.set_printoptions(precision=2, suppress=True, linewidth=90)\n",
    "\n",
    "        sorted_y_pred_decoded_inv = sorted(predicted,key=lambda predicted:predicted[1])\n",
    "        best_box = sorted_y_pred_decoded_inv.pop()\n",
    "        \n",
    "        # Draw the predicted boxes onto the image\n",
    "\n",
    "        # Set the colors for the bounding boxes\n",
    "        colors = plt.cm.hsv(np.linspace(0, 1, n_classes+1)).tolist()\n",
    "        \n",
    "        # TODO: set the classes names (dont remove 'background')\n",
    "        classes = ['background', 'HSM']\n",
    "\n",
    "        plt.figure(figsize=(20,12))\n",
    "        plt.imshow(batch_original_images[i])\n",
    "\n",
    "        current_axis = plt.gca()\n",
    "\n",
    "        xmin = best_box[2]\n",
    "        ymin = best_box[3]\n",
    "        xmax = best_box[4]\n",
    "        ymax = best_box[5]\n",
    "        color = colors[int(best_box[0])]\n",
    "        label = '{}: {:.2f}'.format(classes[int(best_box[0])], best_box[1])\n",
    "        current_axis.add_patch(plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, color='red', fill=False, linewidth=2))  \n",
    "        current_axis.text(xmin, ymin, label, size='x-large', color='white', bbox={'facecolor':color, 'alpha':1.0})\n",
    "        \n",
    "        # save the image with the predicted box\n",
    "        plt.savefig('output\\\\' + str(l+1) + '.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
